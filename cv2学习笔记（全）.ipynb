{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 26 11:39:53 2017\n",
    "\n",
    "@author: situ.st.1\n",
    "\"\"\"\n",
    "\n",
    "import cv2 \n",
    "\n",
    "#读取 \n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/allensu.jpg') \n",
    "#img = cv2.imread('C:/Users/situ.st.1/Pictures/allensu.jpg',0)#灰度图\n",
    "cv2.namedWindow('liege') \n",
    "cv2.imshow('liege', img) \n",
    "cv2.waitKey(0)   #如果不添，在IDLE中执行窗口直接无响应\n",
    "#在命令行中执行的话，则是一闪而过。\n",
    "cv2.destroyAllWindows() #释放窗口\n",
    "\n",
    "#复制\n",
    "img1 = img.copy()\n",
    "                     \n",
    "#保存                   \n",
    "#  第一个参数是保存的路径及文件名，第二个是图像矩阵。\n",
    "#第三个参数针对特定的格式： \n",
    "#对于JPEG，其表示的是图像的质量，用0-100的整数表示，默认为95。   \n",
    "#对于PNG，第三个参数表示的是压缩级别。从0到9,压缩级别越高，图像尺寸越小。默认级别为3：\n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/mylove.png\", img, [int(cv2.IMWRITE_PNG_COMPRESSION), 0])   \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/mylove2.png\", img, [int(cv2.IMWRITE_PNG_COMPRESSION), 9])                \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/mylove3.png\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 5])  \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/mylove4.png\", img, [int(cv2.IMWRITE_JPEG_QUALITY), 100])                    \n",
    "#我咋觉得没啥区别。。     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge by OpenCV\n",
      "(3072L, 3L, 1L)\n",
      "[[[133  45   5]\n",
      "  [133  45   5]\n",
      "  [133  45   5]\n",
      "  ..., \n",
      "  [107  27   2]\n",
      "  [107  27   2]\n",
      "  [107  27   2]]\n",
      "\n",
      " [[133  45   5]\n",
      "  [133  45   5]\n",
      "  [133  45   5]\n",
      "  ..., \n",
      "  [106  26   1]\n",
      "  [105  25   0]\n",
      "  [105  25   0]]\n",
      "\n",
      " [[133  45   5]\n",
      "  [133  45   5]\n",
      "  [133  45   5]\n",
      "  ..., \n",
      "  [105  25   0]\n",
      "  [104  24   0]\n",
      "  [104  24   0]]\n",
      "\n",
      " ..., \n",
      " [[ 15 104  30]\n",
      "  [ 30 119  46]\n",
      "  [ 24 110  40]\n",
      "  ..., \n",
      "  [ 44  88  57]\n",
      "  [ 12  56  25]\n",
      "  [  0  41  10]]\n",
      "\n",
      " [[ 26 115  41]\n",
      "  [ 23 112  39]\n",
      "  [ 21 107  37]\n",
      "  ..., \n",
      "  [  0  37   6]\n",
      "  [ 10  52  21]\n",
      "  [  4  45  17]]\n",
      "\n",
      " [[ 34 123  49]\n",
      "  [ 12 101  28]\n",
      "  [  8  94  24]\n",
      "  ..., \n",
      "  [  0  34   3]\n",
      "  [ 12  52  24]\n",
      "  [  8  48  20]]]\n"
     ]
    }
   ],
   "source": [
    "#访问像素\n",
    "#其中j，i分别表示图像的行和列。对于BGR图像，为：\n",
    "#img[j,i,0]= 255\n",
    "\n",
    "#分离合并通道\n",
    "import cv2  \n",
    "import numpy as np  \n",
    "  \n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/caoyuan.jpg')  \n",
    "b, g, r = cv2.split(img)  \n",
    "cv2.imshow(\"Blue\", b)  \n",
    "cv2.imshow(\"Red\", r)  \n",
    "cv2.imshow(\"Green\", g)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "#或者用数组的方法\n",
    "b = np.zeros((img.shape[0],img.shape[1]), dtype=img.dtype)  \n",
    "g = np.zeros((img.shape[0],img.shape[1]), dtype=img.dtype)  \n",
    "r = np.zeros((img.shape[0],img.shape[1]), dtype=img.dtype)  \n",
    "  \n",
    "b[:,:] = img[:,:,0]  \n",
    "g[:,:] = img[:,:,1]  \n",
    "r[:,:] = img[:,:,2] \n",
    "\n",
    "\n",
    "\n",
    "#通道合并。OpenCV自带的merge函数???作用？？？\n",
    "\n",
    "merged = cv2.merge([b,g,r]) #前面分离出来的三个通道 \n",
    "print \"Merge by OpenCV\"   \n",
    "print merged.strides  \n",
    "print merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#绘制色彩直方图cv2.calcHist\n",
    "\n",
    "#第一个参数必须用方括号括起来。\n",
    "#第二个参数是用于计算直方图的通道，这里使用灰度图计算直方图，所以就直接使用第一个通道0\n",
    "#第三个参数是Mask，这里没有使用，所以用None。\n",
    "#第四个参数是histSize，表示这个直方图分成多少份（即多少个直方柱）。第二个例子将绘出直方图，到时候会清楚一点。\n",
    "#第五个参数是表示直方图中各个像素的值，[0.0, 256.0]表示直方图能表示像素值从0.0到256的像素。\n",
    "#最后是两个可选参数，由于直方图作为函数结果返回了，所以第六个hist就没有意义了（待确定）\n",
    "#最后一个accumulate是一个布尔值，用来表示直方图是否叠加。\n",
    "\n",
    "import cv2      \n",
    "import numpy as np      \n",
    "      \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/splitman.jpg\")      \n",
    "b, g, r = cv2.split(img)   \n",
    "\n",
    "##cv2.calcHist\n",
    "#其中第一个参数必须用方括号括起来。\n",
    "#第二个参数是用于计算直方图的通道，这里使用灰度图计算直方图，所以就直接使用第一个通道；\n",
    "#第三个参数是Mask，这里没有使用，所以用None。\n",
    "#第四个参数是histSize，表示这个直方图分成多少份（即多少个直方柱）。第二个例子将绘出直方图，到时候会清楚一点。\n",
    "#第五个参数是表示直方图中各个像素的值，[0.0, 256.0]表示直方图能表示像素值从0.0到256的像素。\n",
    "\n",
    "   #封装成一个函数                 \n",
    "def calcAndDrawHist(image, color):    \n",
    "    hist= cv2.calcHist([image], [0], None, [256], [0.0,255.0])\n",
    "          #照片 #使用的通道  #没有使用mask #HistSize  #直方图柱的范围     \n",
    "    minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(hist)    \n",
    "    histImg = np.zeros([256,256,3], np.uint8)    \n",
    "    hpt = int(0.9* 256);    \n",
    "        \n",
    "    for h in range(256):    \n",
    "        intensity = int(hist[h]*hpt/maxVal)    \n",
    "        cv2.line(histImg,(h,256), (h,256-intensity), color)    \n",
    "            \n",
    "    return histImg;   \n",
    "\n",
    "if __name__ == '__main__':    #主函数\n",
    "    img = cv2.imread(\"C:/Users/situ.st.1/Pictures/splitman.jpg\")    \n",
    "    b, g, r = cv2.split(img)    \n",
    "    \n",
    "    histImgB = calcAndDrawHist(b, [255, 0, 0])    \n",
    "    histImgG = calcAndDrawHist(g, [0, 255, 0])    \n",
    "    histImgR = calcAndDrawHist(r, [0, 0, 255])    \n",
    "        \n",
    "    cv2.imshow(\"histImgB\", histImgB)    \n",
    "    cv2.imshow(\"histImgG\", histImgG)    \n",
    "    cv2.imshow(\"histImgR\", histImgR)    \n",
    "    cv2.imshow(\"Img\", img)    \n",
    "    cv2.waitKey(0)    \n",
    "    cv2.destroyAllWindows()   \n",
    "\n",
    "\n",
    "#同时绘制三个通道的直方图-\n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/splitman.jpg\") \n",
    "h = np.zeros((256,256,3)) #创建用于绘制直方图的全0图像    \n",
    "         \n",
    "bins = np.arange(256).reshape(256,1) #直方图中各bin的顶点位置    \n",
    "color = [ (255,0,0),(0,255,0),(0,0,255) ] #BGR三种颜色   \n",
    "#for循环是对三个通道遍历一次，每次绘制相应通道的直方图的折线！ \n",
    "for ch, col in enumerate(color):    \n",
    "    originHist = cv2.calcHist([img],[ch],None,[256],[0,256])    \n",
    "    cv2.normalize(originHist, originHist,0,255*0.9,cv2.NORM_MINMAX) \n",
    "    #归一化函数。该函数将直方图的范围限定在0-255×0.9之间\n",
    "    hist=np.int32(np.around(originHist))   \n",
    "    #先将生成的原始直方图中的每个元素四舍六入五凑偶取整\n",
    "    pts = np.column_stack((bins,hist)) \n",
    "#    将直方图中每个bin的值转成相应的坐标\n",
    "    cv2.polylines(h,[pts],False,col) \n",
    "    #根据这些点绘制出折线，\n",
    "#    第三个False参数指出这个折线不需要闭合。第四个参数指定了折线的颜色。\n",
    "h=np.flipud(h)    \n",
    "         \n",
    "cv2.imshow('colorhist',h)    \n",
    "cv2.waitKey(0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0]]\n",
      "[[0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 1 1 1 1 1 1 0]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#形态学处理\n",
    "\n",
    "#形态学处理的核心就是定义结构元素\n",
    "#定义结构元素getStructuringElement函数\n",
    "import cv2      \n",
    "import numpy as np  \n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/heibai.jpg') \n",
    "np.set_printoptions(threshold='nan')\n",
    "element = cv2.getStructuringElement(cv2.MORPH_CROSS,(10,10)) \n",
    "#定义椭圆（MORPH_ELLIPSE）和十字形结构（MORPH_CROSS）长方形 MORPH_RECT\n",
    "print element\n",
    "element = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10,10)) \n",
    "print element\n",
    "\n",
    "\n",
    "#OpenCV定义的结构元素  \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(10, 10))  \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(10, 10))   \n",
    "#腐蚀图像  \n",
    "eroded = cv2.erode(img,kernel)  \n",
    "#显示腐蚀后的图像  \n",
    "cv2.imshow(\"Eroded Image\",eroded);  \n",
    "  \n",
    "#膨胀图像  \n",
    "dilated = cv2.dilate(img,kernel)  \n",
    "#显示膨胀后的图像  \n",
    "cv2.imshow(\"Dilated Image\",dilated);  \n",
    "#原图像  \n",
    "cv2.imshow(\"Origin\", img)  \n",
    "  \n",
    "\n",
    "  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#开运算和闭运算---------------------------\n",
    "#开运算和闭运算就是将腐蚀和膨胀按照一定的次序进行处理。\n",
    "#但这两者并不是可逆的，即先开后闭并不能得到原先的图像。\n",
    "#定义结构元素  \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(5, 5))  \n",
    "  \n",
    "#闭运算（先膨胀再腐蚀）  \n",
    "closed = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)  \n",
    "cv2.imshow(\"Close\",closed);  \n",
    "  \n",
    "#开运算 （先腐蚀后膨胀，去除噪点） \n",
    "opened = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)   \n",
    "cv2.imshow(\"Open\", opened);  \n",
    "  \n",
    "#先闭后开\n",
    "close_open = cv2.morphologyEx(closed,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow(\"close_open\",close_open);       \n",
    "          \n",
    "#先开后闭\n",
    "open_close = cv2.morphologyEx(opened,cv2.MORPH_OPEN,kernel)\n",
    "cv2.imshow(\"open_close\",open_close);           \n",
    "          \n",
    "          \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "#闭运算用来连接被误分为许多小块的对象，而开运算用于移除由图像噪音形成的斑点。\n",
    "#因此，某些情况下可以连续运用这两种运算。\n",
    "#如对一副二值图连续使用闭运算和开运算，将获得图像中的主要对象。\n",
    "#如果想消除图像中的噪声（即图像中的“小点”），也可以对图像先用开运算后用闭运算，不过这样也会消除一些破碎的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用形态学运算检测边和角点--------------------\n",
    "#形态学检测边缘的原理:在膨胀时，图像中的物体会想周围“扩张”；腐蚀时，图像中的物体会“收缩”。\n",
    "#比较这两幅图像，由于其变化的区域只发生在边缘。所以这时将两幅图像相减，得到的就是图像中物体的边缘。\n",
    "import cv2\n",
    "import numpy  as np\n",
    "  \n",
    "image = cv2.imread('C:/Users/situ.st.1/Pictures/caoyuan.jpg',0);\n",
    "cv2.imshow(\"caoyuan\",image);\n",
    "#构造一个3×3的结构元素   \n",
    "element = cv2.getStructuringElement(cv2.MORPH_RECT,(3, 3))  \n",
    "dilate = cv2.dilate(image, element)  \n",
    "erode = cv2.erode(image, element)  \n",
    "  \n",
    "#将两幅图像相减获得边，第一个参数是膨胀后的图像，第二个参数是腐蚀后的图像  \n",
    "result = cv2.absdiff(dilate,erode);  \n",
    "  \n",
    "#上面得到的结果是灰度图，将其二值化以便更清楚的观察结果  \n",
    "retval, result = cv2.threshold(result, 40, 255, cv2.THRESH_BINARY);   \n",
    "#反色，即对二值图每个像素取反  \n",
    "result = cv2.bitwise_not(result);   \n",
    "#显示图像  \n",
    "cv2.imshow(\"result\",result);   \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "#检测拐角原理：先用十字形的结构元素膨胀像素，这种情况下只会在边缘处“扩张”，角点不发生变化。\n",
    "#接着用菱形的结构元素腐蚀原图像，导致只有在拐角处才会“收缩”，而直线边缘都未发生变化。\n",
    "#第二步是用X形膨胀原图像，角点膨胀的比边要多。这样第二次用方块腐蚀时，角点恢复原状，而边要腐蚀的更多。\n",
    "#所以当两幅图像相减时，只保留了拐角处。\n",
    "import cv2  \n",
    "  \n",
    "image = cv2.imread('C:/Users/situ.st.1/Pictures/caoyuan.jpg', 0)  \n",
    "origin = cv2.imread('C:/Users/situ.st.1/Pictures/caoyuan.jpg')  \n",
    "#构造5×5的结构元素，分别为十字形、菱形、方形和X型  \n",
    "cross = cv2.getStructuringElement(cv2.MORPH_CROSS,(5, 5))  \n",
    "#菱形结构元素的定义稍麻烦一些  \n",
    "diamond = cv2.getStructuringElement(cv2.MORPH_RECT,(5, 5))  \n",
    "diamond[0, 0] = 0  \n",
    "diamond[0, 1] = 0  \n",
    "diamond[1, 0] = 0  \n",
    "diamond[4, 4] = 0  \n",
    "diamond[4, 3] = 0  \n",
    "diamond[3, 4] = 0  \n",
    "diamond[4, 0] = 0  \n",
    "diamond[4, 1] = 0  \n",
    "diamond[3, 0] = 0  \n",
    "diamond[0, 3] = 0  \n",
    "diamond[0, 4] = 0  \n",
    "diamond[1, 4] = 0  \n",
    "square = cv2.getStructuringElement(cv2.MORPH_RECT,(5, 5))  \n",
    "x = cv2.getStructuringElement(cv2.MORPH_CROSS,(5, 5))  \n",
    "#使用cross膨胀图像  \n",
    "result1 = cv2.dilate(image,cross)  \n",
    "#使用菱形腐蚀图像  \n",
    "result1 = cv2.erode(result1, diamond)  \n",
    "  \n",
    "#使用X膨胀原图像   \n",
    "result2 = cv2.dilate(image, x)  \n",
    "#使用方形腐蚀图像   \n",
    "result2 = cv2.erode(result2,square)  \n",
    "  \n",
    "#result = result1.copy()  \n",
    "#将两幅闭运算的图像相减获得角   \n",
    "result = cv2.absdiff(result2, result1)  \n",
    "#使用阈值获得二值图  \n",
    "retval, result = cv2.threshold(result, 40, 255, cv2.THRESH_BINARY)  \n",
    "  \n",
    "#在原图上用半径为5的圆圈将点标出。  \n",
    "for j in range(result.size):  \n",
    "    y = j / result.shape[0]   \n",
    "    x = j % result.shape[0]   \n",
    "  \n",
    "    if result[x, y] == 255:  \n",
    "        cv2.circle(image, (y, x), 5, (255,0,0))  \n",
    "  \n",
    "cv2.imshow(\"Result\", image)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#高通滤波器\n",
    "#\n",
    "#检测图像的某个区域，然后根据像素与周围像素的亮度差值来提升(boost)该像素的亮度的滤波器。\n",
    "#核是指一组权重的集合，它会应用在源图像的一个区域，并由此生成目标图像的一个像素。\n",
    "#比如，大小为7的核意味着每49（7 x 7）个源图像的像素会产生目标图像的一个像素。\n",
    "#可把核看作一块覆盖在源图像上可移动的毛玻璃片，玻璃片覆盖区域的光线会按某种方式进行扩散混合后透过去。\n",
    "\n",
    "#在计算完中央像素与周围邻近像素的亮度差值之和以后，如果亮度变化很大，中央像素的亮度会增加（反之则不会）。\n",
    "#换句话说，如果一个像素比它周围的像素更突出，就会提升它的亮度。\n",
    "#这在边缘检测上尤其有效，它会采用一种称为高频提升滤波器(high boost filter)的高通滤波器。\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "kernal_3x3 = np.array([[-1, -1, -1],\n",
    "                       [-1, 8, -1],\n",
    "                       [-1, -1, -1]])\n",
    "kernal_5x5 = np.array([[-1, -1, -1, -1, -1],\n",
    "                       [-1, 1, 2, 1, -1],\n",
    "                       [-1, 2, 4, 2, -1],\n",
    "                       [-1, 1, 2, 1, -1],\n",
    "                       [-1, -1, -1, -1,-1]])\n",
    "\n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/lena.jpg',0) \n",
    "k3 = ndimage.convolve(img, kernal_3x3) \n",
    " # 注：使用ndimage.convolve()时，滤波核的维度应与原始图像的维度相同，故此采用灰度图\n",
    "k5 = ndimage.convolve(img, kernal_5x5)\n",
    "\n",
    "blurred = cv2.GaussianBlur(img, (11, 11), 0)\n",
    "g_hpf = img - blurred\n",
    "cv2.imshow(\"image\", img)\n",
    "cv2.imshow(\"3x3\", k3)\n",
    "cv2.imshow(\"5x5\", k5)\n",
    "cv2.imshow(\"g_hpf\", g_hpf)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#导入模块之后，我们定义一个3x3和一个5x5的核，然后将读入的图像转换为灰度格式。\n",
    "#通常大多数的图像处理会用NumPy来完成，但是这里的情况比较特殊，\n",
    "#因为需要用一个给定的核与图像进行“卷积”(convolve)，但是NumPy碰巧只接受一维数组。\n",
    "#ndimage的convolve()函数支持经典的NumPy数组，cv2模块用这种数组来存储图像。\n",
    "#\n",
    "#还有一种方法可实现高通滤波器：通过对图像应用低通滤波器之后，与原始图像计算差值。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#初级滤波\n",
    "#OpenCV提供的一个通用的2D滤波函数为cv2.filter2D()，滤波函数的使用需要一个核模板，\n",
    "#对图像的滤波操作过程为：将和模板放在图像的一个像素A上，求与之对应的图像上的每个像素点的和，核不同，得到的结果不同，\n",
    "#而滤波的使用核心也是对于这个核模板的使用。\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/lena.jpg\",0) \n",
    "img1 = np.float32(img) #转化数值类型\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "dst = cv2.filter2D(img1,-1,kernel)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#用低通滤波来平滑图像(线性过滤)----------\n",
    "#低通滤波器的目标是降低图像的变化率。\n",
    "#如将每个像素替换为该像素周围像素的均值。这样就可以平滑并替代那些强度变化明显的区域。\n",
    "import cv2  \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/lena.jpg\", 0)  \n",
    "result = cv2.blur(img, (5,5))  \n",
    "  \n",
    "cv2.imshow(\"Origin\", img);\n",
    "cv2.imshow(\"Blur\", result);  \n",
    "  \n",
    "result1 = cv2.boxFilter(img, -1, (5, 5)) #与blur函数完全相同\n",
    "cv2.imshow(\"boxfilter\",result1);\n",
    "#高斯模糊\n",
    "#在某些情况下，需要对一个像素的周围的像素给予更多的重视。因此，可通过分配权重来重新计算这些周围点的值。\n",
    "#这可通过高斯函数（钟形函数，即喇叭形数）的权重方案来解决。\n",
    "#低通滤波与高斯滤波的不同之处在于：低通滤波中，滤波器中每个像素的权重是相同的，即滤波器是线性的。\n",
    "#而高斯滤波器中像素的权重与其距中心像素的距离成比例。\n",
    "gaussianResult = cv2.GaussianBlur(img,(5,5),1.5)  \n",
    "cv2.imshow(\"gauss\",gaussianResult);\n",
    "\n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "#使用中值滤波消除噪点（非线性过滤器）----------------\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "    \n",
    "def salt(img, n):    \n",
    "    for k in range(n):    \n",
    "        i = int(np.random.random() * img.shape[1]);    \n",
    "        j = int(np.random.random() * img.shape[0]);    \n",
    "        if img.ndim == 2:     \n",
    "            img[j,i] = 255    \n",
    "        elif img.ndim == 3:     \n",
    "            img[j,i,0]= 255    \n",
    "            img[j,i,1]= 255    \n",
    "            img[j,i,2]= 255    \n",
    "    return img   \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/lena.jpg\", 0)  \n",
    "result = salt(img, 500)  \n",
    "median = cv2.medianBlur(result, 5)  \n",
    "  \n",
    "  \n",
    "cv2.imshow(\"Salt\", result)  \n",
    "cv2.imshow(\"Median\", median)  \n",
    "  \n",
    "cv2.waitKey(0)  \n",
    "\n",
    "#medianblur函数返回处理结果，第一个参数是待处理图像，第二个参数是孔径的尺寸，一个大于1的奇数。\n",
    "#比如这里是5，中值滤波器就会使用5×5的范围来计算。即对像素的中心值及其5×5邻域组成了一个数值集，对其进行处理计算，当前像素被其中值替换掉。\n",
    "#如果在某个像素周围有白色或黑色的像素，这些白色或黑色的像素不会选择作为中值（最大或最小值不用），而是被替换为邻域值。\n",
    "#由于中值滤波不会处理最大和最小值，所以就不会受到噪声的影响。\n",
    "#相反，如果直接采用blur进行均值滤波，则不会区分这些噪声点，滤波后的图像会受到噪声的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#检测边缘2\n",
    "#Sobel算子（带有方向的过滤器）\n",
    "dst = cv2.Sobel(src, ddepth, dx, dy[, dst[, ksize[, scale[, delta[, borderType]]]]])  \n",
    "#前四个是必须的参数：\n",
    "#第一个参数是需要处理的图像；\n",
    "#第二个参数是图像的深度，-1表示采用的是与原图像相同的深度。目标图像的深度必须大于等于原图像的深度；\n",
    "#dx和dy表示的是求导的阶数，0表示这个方向上没有求导，一般为0、1、2。\n",
    "#其后是可选的参数：\n",
    "#\n",
    "#dst不用解释了；\n",
    "#ksize是Sobel算子的大小，必须为1、3、5、7。\n",
    "#scale是缩放导数的比例常数，默认情况下没有伸缩系数；\n",
    "#delta是一个可选的增量，将会加到最终的dst中，同样，默认情况下没有额外的值加到dst中；\n",
    "#borderType是判断图像边界的模式。这个参数默认值为cv2.BORDER_DEFAULT。\n",
    "#coding=utf-8  \n",
    "import cv2  \n",
    "import numpy as np    \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/caoyuan.jpg\", 0)  \n",
    "  \n",
    "x = cv2.Sobel(img,cv2.CV_16S,1,0)  \n",
    "y = cv2.Sobel(img,cv2.CV_16S,0,1)  \n",
    "  \n",
    "absX = cv2.convertScaleAbs(x)   # 转回uint8  \n",
    "absY = cv2.convertScaleAbs(y)  \n",
    "  \n",
    "dst = cv2.addWeighted(absX,0.5,absY,0.5,0)  \n",
    "#Sobel算子是在两个方向计算的，最后还需要用cv2.addWeighted(...)函数将其组合起来。\n",
    "cv2.imshow(\"absX\", absX)  \n",
    "cv2.imshow(\"absY\", absY)  \n",
    "  \n",
    "cv2.imshow(\"Result\", dst) \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/sobel.jpg\",dst) \n",
    "  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#检测边缘3\n",
    "#Laplacian算子\n",
    "#Sobel算子使用的原理——极值处就是边缘\n",
    "#图像中的边缘区域，像素值会发生“跳跃”，对这些像素求导，在其一阶导数在边缘位置为极值\n",
    "#Laplace函数实现的方法是先用Sobel 算子计算二阶x和y导数，再求和\n",
    "dst = cv2.Laplacian(src, ddepth[, dst[, ksize[, scale[, delta[, borderType]]]]])  \n",
    "#参数解释和sobel一样\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/caoyuan.jpg\", 0)  \n",
    "#img =  cv2.GaussianBlur(img,(5,5),1.5)  #先高斯模糊去噪再用拉普拉斯函数\n",
    "gray_lap = cv2.Laplacian(img,cv2.CV_16S,ksize = 3)  \n",
    "dst = cv2.convertScaleAbs(gray_lap)  \n",
    "  \n",
    "cv2.imshow('laplacian',dst) \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/laplacian.jpg\",dst) \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#canny边缘检测4\n",
    "edge = cv2.Canny(image, threshold1, threshold2[, edges[, apertureSize[, L2gradient ]]])   \n",
    "#第一个参数是需要处理的原图像，该图像必须为单通道的灰度图；\n",
    "#第二个参数是阈值1；\n",
    "#第三个参数是阈值2。\n",
    "#其中较大的阈值2用于检测图像中明显的边缘，但一般情况下检测的效果不会那么完美，边缘检测出来是断断续续的。\n",
    "#所以这时候用较小的第一个阈值用于将这些间断的边缘连接起来。\n",
    "#可选参数中apertureSize就是Sobel算子的大小。\n",
    "#而L2gradient参数是一个布尔值，如果为真，则使用更精确的L2范数进行计算（即两个方向的倒数的平方和再开放），\n",
    "#否则使用L1范数（直接将两个方向导数的绝对值相加）\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "  \n",
    "#Canny函数的使用很简单，只需指定最大和最小阈值即可\n",
    "#首先，由于Canny只能处理灰度图，所以将读取的图像转成灰度图。用高斯平滑处理原图像降噪。\n",
    "#调用Canny函数，指定最大和最小阈值，其中apertureSize默认为3\n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/caoyuan.jpg\", 0)  \n",
    "img = cv2.GaussianBlur(img,(3,3),0)  \n",
    "canny = cv2.Canny(img, 50, 150)  \n",
    "cv2.imwrite(\"C:/Users/situ.st.1/Pictures/canny.jpg\",canny)\n",
    "  \n",
    "cv2.imshow('Canny', canny)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "#厉害了！！！！！！\n",
    "#这个程序只是静态的，在github上有一个可以在运行时调整阈值大小的程序。其代码如下：\n",
    "import cv2  \n",
    "import numpy as np  \n",
    "  \n",
    "def CannyThreshold(lowThreshold):  \n",
    "    detected_edges = cv2.GaussianBlur(gray,(3,3),0)  \n",
    "    detected_edges = cv2.Canny(detected_edges,lowThreshold,lowThreshold*ratio,apertureSize = kernel_size)  \n",
    "    dst = cv2.bitwise_and(img,img,mask = detected_edges)  # just add some colours to edges from original image.  \n",
    "    cv2.imshow('canny demo',dst)  \n",
    "  \n",
    "lowThreshold = 0  \n",
    "max_lowThreshold = 100  \n",
    "ratio = 3  \n",
    "kernel_size = 3  \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/caoyuan.jpg\")  \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  \n",
    "  \n",
    "cv2.namedWindow('canny demo')  \n",
    "  \n",
    "cv2.createTrackbar('Min threshold','canny demo',lowThreshold, max_lowThreshold, CannyThreshold)  \n",
    "  \n",
    "CannyThreshold(0)  # initialization  \n",
    "if cv2.waitKey(0) == 27:  \n",
    "    cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#直方图均方化（增强对比度）\n",
    "\n",
    "#在图像处理中，直方图均衡化一般用来均衡图像的强度，或增加图像的对比度。\n",
    "#在介绍使用直方图均衡化来拉伸图像的直方图之前，先介绍使用查询表的方法。\n",
    "#观察上图中原始图像的直方图，很容易发现大部分强度值范围都没有用到。\n",
    "#因此先检测图像非0的最低（imin）强度值和最高（imax）强度值。\n",
    "#将最低值imin设为0，最高值imax设为255。中间的按255.0*(i-imin)/(imax-imin)+0.5)的形式设置。\n",
    "image = cv2.imread(\"C:/Users/situ.st.1/Pictures/caoyuan.jpg\", 0) \n",
    "cv2.imshow(\"origin\",image); \n",
    "lut = np.zeros(256, dtype = image.dtype )#创建空的查找表  \n",
    "hist= cv2.calcHist([image], #计算图像的直方图  \n",
    "    [0], #使用的通道  \n",
    "    None, #没有使用mask  \n",
    "    [256], #it is a 1D histogram  \n",
    "    [0.0,255.0])  \n",
    "      \n",
    "minBinNo, maxBinNo = 0, 255  \n",
    "#计算从左起第一个不为0的直方图位置  \n",
    "for binNo, binValue in enumerate(hist):  \n",
    "    if binValue != 0:  \n",
    "        minBinNo = binNo  \n",
    "        break  \n",
    "#计算从右起第一个不为0的直方图位置  \n",
    "for binNo, binValue in enumerate(reversed(hist)):  \n",
    "    if binValue != 0:  \n",
    "        maxBinNo = 255-binNo  \n",
    "        break  \n",
    "print minBinNo, maxBinNo  \n",
    "  \n",
    "#生成查找表，方法来自参考文献1第四章第2节  \n",
    "for i,v in enumerate(lut):  \n",
    "    print i  \n",
    "    if i < minBinNo:  \n",
    "        lut[i] = 0  \n",
    "    elif i > maxBinNo:  \n",
    "        lut[i] = 255  \n",
    "    else:  \n",
    "        lut[i] = int(255.0*(i-minBinNo)/(maxBinNo-minBinNo)+0.5)  \n",
    "\n",
    "#计算  \n",
    "result = cv2.LUT(image, lut)  \n",
    "cv2.imshow(\"Result\", result)  \n",
    "cv2.imwrite(\"LutImage.jpg\", result)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "#直方图均衡化之OpenCV函数实现\n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/caoyuan.jpg',0)  \n",
    "equ = cv2.equalizeHist(img)  \n",
    "cv2.imshow('equ',equ)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#轮廓检测\n",
    "\n",
    "#cv2.findContours()函数接受的参数为二值图，即黑白的（不是灰度图），\n",
    "# 所以读取的图像要先转成灰度的，再转成二值图\n",
    "import cv2  \n",
    "  \n",
    "img = cv2.imread('C:/Users/situ.st.1/Pictures/heibai.jpg')  \n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  \n",
    "ret, binary = cv2.threshold(gray,127,255,cv2.THRESH_BINARY)  \n",
    "  \n",
    "image,contours, hierarchy = cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  \n",
    "cv2.drawContours(img,contours,-1,(0,0,255),3)  \n",
    "  \n",
    "cv2.imshow(\"img\", img)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.imshow(\"binary\", binary) \n",
    "cv2.waitKey(0)   \n",
    "contours, hierarchy = cv2.findContours(binary,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)  \n",
    "cv2.imshow(\"binary2\", binary)  \n",
    "cv2.waitKey(0)  \n",
    "\n",
    "img = np.zeros((200, 200), dtype = np.uint8)   # 创建一个200x200大小的黑色空白图像，\n",
    "img[50:150, 50:150] = 255                      # 在图像的中央放置一个白色方块\n",
    "\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)  #对图像进行二值化操作\n",
    "image, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  # 寻找轮廓\n",
    "color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)  # 颜色空间转换\n",
    "img = cv2.drawContours(color, contours, -1, (0, 255, 0), 2)  # 画出轮廓，-1,表示所有轮廓，画笔颜色为(0, 255, 0)，即Green，粗细为3\n",
    "cv2.imshow(\"contours\",color)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#findContours()函数有三个参数：输入图像、层次类型和轮廓逼近方法。\n",
    "#这个函数会修改输入图像，因此建议使用原始图像的一份拷贝（如：通过img.copy()来作为输入图像）。\n",
    "#由函数返回的层次树相当重要：cv2.RETR_TREE参数会得到图像中轮廓的整体层次结构，以此来建立轮廓之间的“关系”。\n",
    "#如果只想得到最外面的轮廓，可使用cv2.RETR_EXTERNAL。\n",
    "#这对消除包含在其他轮廓中的轮廓很有用（如在大多数情形下，不需要检测一个目标包含在另一个与之相同的目标里面）\n",
    "#\n",
    "#findContours()函数有三个返回值：修改后的图像、图像的轮廓以及它们的层次。\n",
    "#            使用轮廓来画出图像的彩色版本（即把轮廓画成绿色），并显示出来。\n",
    "#\n",
    "#cv2.threshold()简单阈值\n",
    "#　　这个函数有四个参数，第一个原图像，第二个进行分类的阈值，第三个是高于（低于）阈值时赋予的新值，\n",
    "#  第四个是一个方法选择参数，常用的有： \n",
    "#　　　　cv2.THRESH_BINARY（黑白二值） \n",
    "#　　　　cv2.THRESH_BINARY_INV（黑白二值反转） \n",
    "#　　　　cv2.THRESH_TRUNC （得到的图像为多像素值） \n",
    "#　　　　cv2.THRESH_TOZERO \n",
    "#　　　　cv2.THRESH_TOZERO_INV \n",
    "#该函数有两个返回值，第一个retVal（得到的阈值（在后面一个方法中会用到）），第二个就是阈值化后的图像。\n",
    "#cvCvtColor(...)是Opencv里的颜色空间转换函数，可以实现RGB颜色向HSV，HSI等颜色空间的转换，也可以转换为灰度图像。\n",
    "#参数CV_RGB2GRAY是RGB到gray。参数 CV_GRAY2RGB是gray到RGB.处理结果是彩色的，则转灰色就是了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#边界框、最小矩形面积、最小闭圆de轮廓检测---------------\n",
    "#绘制矩形\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.zeros((512,512,3),np.uint8)  #生成一个空彩色图像\n",
    "cv2.rectangle(img,(20,20),(411,411),(55,255,155),5)\n",
    "plt.imshow(img,'brg')\n",
    "plt.show()\n",
    "\n",
    "img = cv2.pyrDown(cv2.imread('C:/Users/situ.st.1/Pictures/heibai.jpg', cv2.IMREAD_UNCHANGED))\n",
    "ret, thresh = cv2.threshold(cv2.cvtColor(img.copy(), cv2.COLOR_BGR2GRAY), 127, 255, cv2.THRESH_BINARY)\n",
    "image, contours, hier = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for c in contours:\n",
    "    # find bounding box coordinates\n",
    "    # 现计算出一个简单的边界框\n",
    "    x, y, w, h = cv2.boundingRect(c)   # 将轮廓信息转换成(x, y)坐标，并加上矩形的高度和宽度\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 0), 2)  # 画出矩形\n",
    "\n",
    "    # find minimum area\n",
    "    # 计算包围目标的最小矩形区域\n",
    "    rect = cv2.minAreaRect(c)\n",
    "    # calculate coordinate of the minimum area rectangle\n",
    "    box = cv2.boxPoints(rect)\n",
    "    # normalize coordinates to integers\n",
    "    box =np.int0(box)\n",
    "    # 注：OpenCV没有函数能直接从轮廓信息中计算出最小矩形顶点的坐标。所以需要计算出最小矩形区域，\n",
    "    # 然后计算这个矩形的顶点。由于计算出来的顶点坐标是浮点型，但是所得像素的坐标值是整数（不能获取像素的一部分），\n",
    "    # 所以需要做一个转换\n",
    "    # draw contours\n",
    "    cv2.drawContours(img, [box], 0, (0, 0, 255), 3)  # 画出该矩形\n",
    "\n",
    "    # calculate center and radius of minimum enclosing circle\n",
    "    (x, y), radius = cv2.minEnclosingCircle(c)  # 会返回一个二元组，第一个元素为圆心的坐标组成的元组，第二个元素为圆的半径值。\n",
    "    # cast to integers\n",
    "    center = (int(x), int(y))\n",
    "    radius = int(radius)\n",
    "    # draw the circle\n",
    "    img = cv2.circle(img, center, radius, (0, 255, 0), 2)\n",
    "\n",
    "cv2.drawContours(img, contours, -1, (255, 0, 0), 1)\n",
    "cv2.imshow(\"contours\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#cv2.drawContours(img, [box], 0, (0, 0, 255), 3)：\n",
    "#首先，该函数与所有绘图函数一样，它会修改源图像。\n",
    "#其次，该函数的第二个参数接收一个保存着轮廓的数组，从而可以在一次操作中绘制一系列的轮廓。\n",
    "#因此如果只有一组点来表示多边形轮廓，就需要把这组点放到一个数组里。\n",
    "#第三个参数是要绘制的轮廓数组的索引：-1表示绘制所有的轮廓，否则只会绘制轮廓数组里指定的轮廓。\n",
    "#大多数绘图函数把绘图的颜色和密度(thickness)放在最后两个参数里。\n",
    "\n",
    "#函数cv2.pyrDown()是从一个高分辨率图像变成低分辨率图像的。cv2.pyrDown()函数接受3个参数：\n",
    "#\n",
    "#tmp: 当前图像，初始化为原图像 src 。\n",
    "#dst: 目的图像( 显示图像，为输入图像的一半)\n",
    "#Size( tmp.cols/2, tmp.rows/2 ) :目的图像大小， 既然我们是向下采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#直线检测-------------------------\n",
    "#画直线\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.zeros((512,512),np.uint8)#生成一个空灰度图像\n",
    "cv2.line(img,(0,0),(511,511),255,5)\n",
    "plt.imshow(img,'gray')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#霍夫变换检测直线\n",
    "import cv2  \n",
    "import numpy as np    \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/road.jpg\", 0)  \n",
    "  \n",
    "img = cv2.GaussianBlur(img,(3,3),0)  \n",
    "edges = cv2.Canny(img, 50, 150, apertureSize = 3)  \n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,118) #这里对最后一个参数使用了经验型的值  \n",
    "result = img.copy()  \n",
    "for line in lines[0]:  \n",
    "    rho = line[0] #第一个元素是距离rho  \n",
    "    theta= line[1] #第二个元素是角度theta  \n",
    "    print rho  \n",
    "    print theta  \n",
    "    if  (theta < (np.pi/4. )) or (theta > (3.*np.pi/4.0)): #垂直直线  \n",
    "                #该直线与第一行的交点  \n",
    "        pt1 = (int(rho/np.cos(theta)),0)  \n",
    "        #该直线与最后一行的焦点  \n",
    "        pt2 = (int((rho-result.shape[0]*np.sin(theta))/np.cos(theta)),result.shape[0])  \n",
    "        #绘制一条白线  \n",
    "        cv2.line( result, pt1, pt2, (255))  \n",
    "    else: #水平直线  \n",
    "        # 该直线与第一列的交点  \n",
    "        pt1 = (0,int(rho/np.sin(theta)))  \n",
    "        #该直线与最后一列的交点  \n",
    "        pt2 = (result.shape[1], int((rho-result.shape[1]*np.cos(theta))/np.sin(theta)))  \n",
    "        #绘制一条直线  \n",
    "        cv2.line(result, pt1, pt2, (255), 1)  \n",
    "  \n",
    "cv2.imshow('Canny', edges )  \n",
    "cv2.imshow('Result', result)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  \n",
    "\n",
    "\n",
    "#概率霍夫变换\n",
    "#观察前面的例子得到的结果图片，其中Hough变换看起来就像在图像中查找对齐的边界像素点集合。\n",
    "#但这样会在一些情况下导致虚假检测，如像素偶然对齐或多条直线穿过同样的对齐像素造成的多重检测。\n",
    "#\n",
    "#要避免这样的问题，并检测图像中分段的直线（而不是贯穿整个图像的直线）\n",
    "#就诞生了Hough变化的改进版，即概率Hough变换（Probabilistic Hough）\n",
    "#函数cv2.HoughLinesP()是一种概率直线检测，我们知道，原理上讲hough变换是一个耗时耗力的算法，\n",
    "#尤其是每一个点计算，即使经过了canny转换了有的时候点的个数依然是庞大的，这个时候我们采取一种概率挑选机制，不是所有的点都计算，\n",
    "#而是随机的选取一些个点来计算，相当于降采样了。这样的话我们的阈值设置上也要降低一些。\n",
    "#在参数输入输出上，输入不过多了两个参数：minLineLengh(线的最短长度，比这个短的都被忽略)和MaxLineCap\n",
    "#（两条直线之间的最大间隔，小于此值，认为是一条直线）。输出上也变了，不再是直线参数的，这个函数输出的直接就是直线点的坐标位置，\n",
    "#这样可以省去一系列for循环中的由参数空间到图像的实际坐标点的转换。\n",
    "#coding=utf-8  \n",
    "import cv2  \n",
    "import numpy as np    \n",
    "  \n",
    "img = cv2.imread(\"C:/Users/situ.st.1/Pictures/line.jpg\")  \n",
    "  \n",
    "img = cv2.GaussianBlur(img,(3,3),0)  \n",
    "edges = cv2.Canny(img, 50, 150, apertureSize = 3)  \n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,118)  \n",
    "result = img.copy()  \n",
    "  \n",
    "#经验参数  \n",
    "minLineLength = 200  \n",
    "maxLineGap = 15  \n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,80,minLineLength,maxLineGap)  \n",
    "for x1,y1,x2,y2 in lines[0]:  \n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)  \n",
    "  \n",
    "cv2.imshow('Result', img)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#圆检测--------------------------\n",
    "#OpenCV的HoughCircles函数可用来检测圆，它与使用HoughLines函数类似。\n",
    "#像用来决定删除或保留直线的两个参数minLineLength和maxLineGap一样，\n",
    "#HoughCircles有一个圆心间的最小距离和圆的最小及最大半径。\n",
    "\n",
    "\n",
    "#画圆\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = np.zeros((512,512,3),np.uint8)#生成一个空彩色图像\n",
    "cv2.circle(img,(100,100),50,(55,255,155),5)\n",
    "plt.imshow(img,'brg')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "planets = cv2.imread(\"C:/Users/situ.st.1/Pictures/starball.jpg\")\n",
    "gray_img = cv2.cvtColor(planets, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.medianBlur(gray_img, 5)\n",
    "cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "circles = cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 120, param1=100, param2 = 30, minRadius = 0,  maxRadius = 0)\n",
    "circles = np.uint16(np.around(circles))\n",
    "\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(planets, (i[0], i[1]), i[2],(0, 255, 0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(planets, (i[0], i[1]), 2, (0, 0,255), 3)\n",
    "\n",
    "cv2.imwrite(\"planets_circles.jpg\",planets)\n",
    "cv2.imshow(\"HoughCircles\", planets)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
